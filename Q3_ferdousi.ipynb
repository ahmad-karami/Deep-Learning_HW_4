{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import GPT2Tokenizer, AutoModelForCausalLM ,GPT2Model\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AdamW\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "import os\n",
        "import numpy as np\n",
        "model_name = \"HooshvareLab/gpt2-fa\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
      ],
      "metadata": {
        "id": "cpwHNRqW6ozv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiARh2wphytd",
        "outputId": "b65ee177-5c12-4f64-c668-7f2a46bae628"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.encode(\"<sep>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gjyC7hAlrOW",
        "outputId": "274a0a72-a92d-45e5-ad85-c228f5c73359"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_I3xGpV5M2M"
      },
      "source": [
        "(آ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1M0cbjY5M2O",
        "outputId": "9a18630a-65bd-43fb-f1b2-31d19246bfa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "کزین برتر اندیشه برنگذرد<sep>\n",
            "به نام خداوند جان و خرد<sep>\n",
            "num of verses: 49608\n",
            "num of verses: 49608\n"
          ]
        }
      ],
      "source": [
        "A = []\n",
        "B = []\n",
        "# Open the file\n",
        "with open('ferdousi.txt', 'r') as file:\n",
        "    # Enumerate the lines, line_num is the line number and line is the line itself\n",
        "    for line_num, line in enumerate(file, start=0):\n",
        "        # If the line number is odd\n",
        "        if line_num % 2 != 1:\n",
        "            A.append(line.strip()+'<sep>')\n",
        "        # If the line number is even\n",
        "        else:\n",
        "            B.append(line.strip()+'<sep>')\n",
        "\n",
        "# Now, 'A' contains the odd lines and 'B' contains the even lines\n",
        "A ,B= A[1:], B[1:]\n",
        "\n",
        "\n",
        "print(B[0])\n",
        "print(A[0])\n",
        "print('num of verses:',len(A))\n",
        "print('num of verses:',len(B))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokenized = tokenizer(A, return_tensors='pt', padding=True, truncation=False)\n",
        "target_tokenized = tokenizer(B, return_tensors='pt', padding=True, truncation=False)"
      ],
      "metadata": {
        "id": "x3fSG0q6aJff"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_input = input_tokenized['input_ids']\n",
        "data_target =target_tokenized['input_ids']\n",
        "attention_input = input_tokenized['attention_mask']\n",
        "attention_target = target_tokenized['attention_mask']\n",
        "\n",
        "input_train, input_test, target_train, target_test, input_attention_train , input_attention_test    = train_test_split(data_input,\n",
        "                                                                      data_target, attention_input,test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "vKMuSyLtaxPt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vers1 = tokenizer.decode(input_train[0], skip_special_tokens=True)\n",
        "vers2 = tokenizer.decode(target_train[0], skip_special_tokens=True)\n",
        "print(vers1)\n",
        "print(vers2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEFcr3_nbq1K",
        "outputId": "2f675c1a-344d-4325-c057-c374ce4661f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "وگر در میان دو رویه سپاه <sep>\n",
            "بگردی بلاف از پی نام و جاه <sep>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustumeDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_mask_input, target_ids):\n",
        "        self.input_ids = input_ids\n",
        "        self.target_ids = target_ids\n",
        "        self.attention_mask_input = attention_mask_input\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attention_mask_input[idx], self.target_ids[idx]\n",
        "\n",
        "# Create dataset\n",
        "train_set = CustumeDataset(input_train, input_attention_train, target_train)\n",
        "test_set = CustumeDataset(input_test, input_attention_test, target_test)\n",
        "\n",
        "# Create dataloader\n",
        "trainloader = DataLoader(train_set, batch_size=32, shuffle=True,num_workers =2)\n",
        "testloader = DataLoader(test_set, batch_size=32, shuffle=True,num_workers =2)"
      ],
      "metadata": {
        "id": "QytXakyYeeB1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "config = GPT2Config.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name, config=config)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "6cIQHZL4lU2F"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data,attention,target in trainloader:\n",
        "  data = data.to(device)\n",
        "  attention = attention.to(device)\n",
        "  target = target.to(device)\n",
        "  break"
      ],
      "metadata": {
        "id": "SimU_J026MZQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.generate(data,max_length=26)\n",
        "generated_text = tokenizer.decode(output[10], skip_special_tokens=True)\n",
        "input_text = tokenizer.decode(data[10], skip_special_tokens=True)\n",
        "print((input_text))\n",
        "print(generated_text[len(input_text):])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZkGOCzdgNZ9",
        "outputId": "0cf41342-7c50-40f2-a783-f0abfba9f1b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ز من باد بر شاه ایران درود <sep>\n",
            "  است که در آن از دو واژهٔ «م» و «\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def val_loop(testloader,model,loss_function):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for i, (inputs,attention, targets) in enumerate(testloader):\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        attention = attention.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs,attention_mask=attention, labels=targets)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Reshape the logits and targets and compute the loss\n",
        "        return loss_function(logits.view(-1, logits.size(-1)), targets.view(-1))\n"
      ],
      "metadata": {
        "id": "dGxDUE_AU7YF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters() , lr= 0.001 , eps= 1e-8 )\n",
        "min_val_loss = float('inf')\n",
        "# Number of training epochs\n",
        "epochs = 50\n",
        "n = 0\n",
        "itter = 0\n",
        "val_loss = []\n",
        "mean_val_losses = []\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for (inputs,attention, targets) in tqdm(trainloader):\n",
        "        itter += 1\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        attention = attention.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs,attention_mask=attention, labels=targets)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Reshape the logits and targets and compute the loss\n",
        "        loss = loss_function(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        # Evaluation\n",
        "        if itter % 100 == 0:\n",
        "            val_loss.append(val_loop(testloader,model,loss_function).item())\n",
        "            if len(val_loss)<10:\n",
        "              val_loss = 10*val_loss\n",
        "\n",
        "            mean_val_loss = np.mean(val_loss[-10:])\n",
        "            mean_val_losses.append(mean_val_loss)\n",
        "\n",
        "            if len(mean_val_losses) > 1:\n",
        "                if mean_val_losses[-2] > mean_val_losses[-1]:\n",
        "                  n = 0\n",
        "                  # Save the model\n",
        "                  checkpoint = {'model_state_dict': model.state_dict(),\n",
        "                      'optimizer_state_dict': optimizer.state_dict()}\n",
        "\n",
        "                elif mean_val_losses[-2] <= mean_val_losses[-1]:\n",
        "                    n+=1\n",
        "                    print(f\"Validation loss is increasing:{val_loss[-1]}\")\n",
        "                if n == 3 :\n",
        "                  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "                  break\n",
        "    if n == 3:\n",
        "      break\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss/len(trainloader):.4f}, Validation Loss: {val_loss[-1]/len(testloader):.4f}')\n",
        "torch.save(checkpoint, \"checkpoint.pth\")\n",
        "    # if val_loss < min_val_loss:\n",
        "    #     # Save the model\n",
        "    #     checkpoint = {'model_state_dict': model.state_dict(),\n",
        "    #         'optimizer_state_dict': optimizer.state_dict()}\n",
        "    #     torch.save(checkpoint, \"checkpoint.pth\")\n",
        "    #     min_val_loss = val_loss\n",
        "    #     n = 0\n",
        "    # elif n == 2:\n",
        "    #   model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    #   optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    #   break\n",
        "    # else: n +=1\n",
        "\n",
        "# files.download('checkpoint.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvUTTuGhnT8H",
        "outputId": "42d31aad-ebb6-4b57-d613-0e1e633d9f3e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1396/1396 [03:37<00:00,  6.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Training Loss: 3.7427, Validation Loss: 0.0237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 5/1396 [00:01<05:14,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss is increasing:3.664842128753662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 805/1396 [02:05<01:49,  5.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss is increasing:3.6941637992858887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1396/1396 [03:36<00:00,  6.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/50], Training Loss: 3.5046, Validation Loss: 0.0228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 109/1396 [00:18<03:52,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss is increasing:3.647052526473999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 209/1396 [00:33<03:58,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss is increasing:3.6896321773529053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 307/1396 [00:48<02:53,  6.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss is increasing:3.7954695224761963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if 'checkpoint.pth' in os.listdir():\n",
        "#   checkpoint = torch.load('checkpoint.pth')\n",
        "#   model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#   optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#   print('pre_train model is exist')\n",
        "# torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "_B0H4VgH3t_6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (inputs,attention, targets) in enumerate(trainloader):\n",
        "   inputs = inputs.to(device)\n",
        "   targets = targets.to(device)\n",
        "   attention = attention.to(device)\n",
        "   break"
      ],
      "metadata": {
        "id": "0x6yaQmd4ooO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Generating for training data')\n",
        "generated_text = model.generate(inputs,max_length=26,\n",
        "        temperature=0.7,num_beams=10,\n",
        "        no_repeat_ngram_size=2,\n",
        "        top_k=50,top_p=0.95,\n",
        "        pad_token_id=tokenizer.pad_token_id)\n",
        "for j in range(20):\n",
        "        input_text = tokenizer.decode(inputs[j], skip_special_tokens=True)\n",
        "        output_text = tokenizer.decode(generated_text[j], skip_special_tokens=True)\n",
        "        print(f\"Input{j}:     {input_text.replace('<sep>','')}\")\n",
        "        print(f\"Generated{j}: {output_text.replace('<sep>','')[0:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8OI_h-z34yq",
        "outputId": "fd23b9cf-3e6f-4452-f99c-9203c0760e3c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating for training data\n",
            "Input0:     همم گنج و بوم است و هم چارپای \n",
            "Generated0: همم گنج و بوم است و هم چارپای     گاه   و   به و و به \n",
            "Input1:     بریزم ز تن خون انباردار \n",
            "Generated1: بریزم ز تن خون انباردار   خوار   گار و   کارزار   خوار\n",
            "Input2:     نهادند سوی فرامرز روی \n",
            "Generated2: نهادند سوی فرامرز روی    و و    گاه می نه و و\n",
            "Input3:     ازان تازی اسپان کش آمد گزین \n",
            "Generated3: ازان تازی اسپان کش آمد گزین   چین    چین   کین کین   زمین زمین \n",
            "Input4:     پیاده بیامد به نزدیک شاه \n",
            "Generated4: پیاده بیامد به نزدیک شاه     گاه گاه   راه راه و   سپاه \n",
            "Input5:     به تیزی بیامد به نزدیک شاه \n",
            "Generated5: به تیزی بیامد به نزدیک شاه   گاه    کلاه راه   گاه   راه به\n",
            "Input6:     خدای جهان را نباشد نیاز \n",
            "Generated6: خدای جهان را نباشد نیاز    نیاز نیاز و گاه باز   باز نیاز\n",
            "Input7:     کسی را ندانم که روز نبرد \n",
            "Generated7: کسی را ندانم که روز نبرد   گرد    گرد  ژ و   کرد نبرد کرد\n",
            "Input8:     بر رستم آمد همانگاه گیو \n",
            "Generated8: بر رستم آمد همانگاه گیو   نیو   و و   نیو   گی گی\n",
            "Input9:     به کردار شیرست آهنگ اوی \n",
            "Generated9: به کردار شیرست آهنگ اوی    روی روی    جوی   و   اوی و\n",
            "Input10:     به دل گفت پنهان شود آفتاب \n",
            "Generated10: به دل گفت پنهان شود آفتاب    آب خواب   خواب و    شتاب آب\n",
            "Input11:     همه راستی خواهم و نیکویی \n",
            "Generated11: همه راستی خواهم و نیکویی     و گاه گاه به و   به \n",
            "Input12:     به ایرانیان گفت کاین خون کیست \n",
            "Generated12: به ایرانیان گفت کاین خون کیست   ستست   پستستستپست   کیستست\n",
            "Input13:     دوان اورمزد از میانه برفت \n",
            "Generated13: دوان اورمزد از میانه برفت  فت    جفتفتفت جفت جفت  فت نه \n",
            "Input14:     همی خون خروشید خواهر ز درد \n",
            "Generated14: همی خون خروشید خواهر ز درد  ورد    نبرد کرد زرد   لا لا   زرد\n",
            "Input15:     بدو باز خواندند لشکرش را \n",
            "Generated15: بدو باز خواندند لشکرش را   را    گاهرد   را را به و\n",
            "Input16:     که باری کسی را ز ایران سپاه \n",
            "Generated16: که باری کسی را ز ایران سپاه     کلاه گاه و   شاه   راه   گاه\n",
            "Input17:     بلاش آن زمان تخت زرین نهاد \n",
            "Generated17: بلاش آن زمان تخت زرین نهاد  اد    داد یاد یاد   نهاد یاد نژاد\n",
            "Input18:     هیونی بتازید تا رزمگاه \n",
            "Generated18: هیونی بتازید تا رزمگاه   راه    گاه سپاه   شاه   سپاه شاه\n",
            "Input19:     که یزدان مرا زندگانی دراز \n",
            "Generated19: که یزدان مرا زندگانی دراز    نیاز    باز گاه باز   راز نیاز\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (inputs,attention, targets) in enumerate(testloader):\n",
        "   inputs = inputs.to(device)\n",
        "   targets = targets.to(device)\n",
        "   attention = attention.to(device)\n",
        "   break"
      ],
      "metadata": {
        "id": "R1Uvs0_GrA0T"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Generating for test data')\n",
        "generated_text = model.generate(inputs,max_length=26,\n",
        "        temperature=0.7,num_beams=10,\n",
        "        no_repeat_ngram_size=2,\n",
        "        top_k=20,top_p=0.95,\n",
        "        pad_token_id=tokenizer.pad_token_id)\n",
        "for j in range(generated_text.shape[0]):\n",
        "        input_text = tokenizer.decode(inputs[j], skip_special_tokens=True)\n",
        "        output_text = tokenizer.decode(generated_text[j], skip_special_tokens=True)\n",
        "        print(f\"Input{j}:     {input_text.replace('<sep>','')}\")\n",
        "        print(f\"Generated{j}: {output_text.replace('<sep>','')[0:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_45VYPituoEs",
        "outputId": "441a4eec-4ee3-48a3-f8dc-2277a69c4570"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating for test data\n",
            "Input0:     نباید که در پیش خسرو شود \n",
            "Generated0: نباید که در پیش خسرو شود   واندواندواند  شود شودواند نماند  \n",
            "Input1:     همان به که او را برپهلوان \n",
            "Generated1: همان به که او را برپهلوان   و    و   دل به بر   بک\n",
            "Input2:     و گر شاه و فرزانگان این به جای \n",
            "Generated2: و گر شاه و فرزانگان این به جای     پایمای   و و   رهن  مای\n",
            "Input3:     درفش سرافراز خاقان و تاج \n",
            "Generated3: درفش سرافراز خاقان و تاج    عاج گاه عاج و   تاج تاج تاج عاج\n",
            "Input4:     بیامد چو نزدیک ایشان رسید \n",
            "Generated4: بیامد چو نزدیک ایشان رسید    دید دید   کشید   بدید   برکشید\n",
            "Input5:     چنان بد که روزی به نخچیرگاه \n",
            "Generated5: چنان بد که روزی به نخچیرگاه     گاه شاه راه سپاه و   و\n",
            "Input6:     چو گشتاسپ را دید بر تخت عاج \n",
            "Generated6: چو گشتاسپ را دید بر تخت عاج   تاج    عاج عاج و تاج   تاج تاج عاج\n",
            "Input7:     بیاراست پیلان و برخاست غو \n",
            "Generated7: بیاراست پیلان و برخاست غو   و    تو نو   نو راست   و\n",
            "Input8:     ز طایر یکی دختش آمد چو ماه \n",
            "Generated8: ز طایر یکی دختش آمد چو ماه   و    آمد بودش کرد   و\n",
            "Input9:     بماند ز پیوند پیمان ما \n",
            "Generated9: بماند ز پیوند پیمان ما   ما ما    گاه من و   ما و\n",
            "Input10:     بگفت آنک این رنجم از یک تنست \n",
            "Generated10: بگفت آنک این رنجم از یک تنست     رگ   پر   و  ست من و\n",
            "Input11:     ز گرد سواران در آن پهن دشت \n",
            "Generated11: ز گرد سواران در آن پهن دشت     دشتگ دشتگذشت  گذشت گشت\n",
            "Input12:     زدم بر سرش گرزهٔ گاو چهر \n",
            "Generated12: زدم بر سرش گرزهٔ گاو چهر   و    من به   و   مهر مهر \n",
            "Input13:     به گشتاسپ آگاهی آمد ز راه \n",
            "Generated13: به گشتاسپ آگاهی آمد ز راه    شاه   گاه    کلاه و   راه شاه\n",
            "Input14:     هر آنکس کجا باشد او بدسگال \n",
            "Generated14: هر آنکس کجا باشد او بدسگال     گاه بودزد و و   بد \n",
            "Input15:     سپهدار پیران بدان شاد شد \n",
            "Generated15: سپهدار پیران بدان شاد شد  اد    داد یاد یاد   شد شاد \n",
            "Input16:     چوبرزد سرازکوه زرد آفتاب \n",
            "Generated16: چوبرزد سرازکوه زرد آفتاب   آب    خواب و   شتاب خواب   و\n",
            "Input17:     زیانی که بودش همه باز داد \n",
            "Generated17: زیانی که بودش همه باز داد   یاد    یاد یاد   داد کرد  اد\n",
            "Input18:     چو اندرز پیران نهادند پیش \n",
            "Generated18: چو اندرز پیران نهادند پیش    خویش    پیش گاه خویش و و \n",
            "Input19:     بدارید و با جان برابر کنید \n",
            "Generated19: بدارید و با جان برابر کنید     کنید گاهند و  اره کنید\n",
            "Input20:     بشد هوش از آن مرد رزم آزمای \n",
            "Generated20: بشد هوش از آن مرد رزم آزمای    پای جای به و   باز   و\n",
            "Input21:     ببود آن شب و بامداد پگاه \n",
            "Generated21: ببود آن شب و بامداد پگاه   راه    گاه و   سپاه   شاه   و\n",
            "Input22:     یکی بانگ برزد براندش ز پیش \n",
            "Generated22: یکی بانگ برزد براندش ز پیش   و    بیش کیش   خویش پیش خویش\n",
            "Input23:     که ایدون به بالین شیرآمدی \n",
            "Generated23: که ایدون به بالین شیرآمدی   بس    کس و   بس بس کس کس \n",
            "Input24:     بسالار گفت آنچ فرمان دهی \n",
            "Generated24: بسالار گفت آنچ فرمان دهی    ی گاهی   تهی  ن و\n",
            "Input25:     ازو هیچ گشتاسپ نشکیفتی \n",
            "Generated25: ازو هیچ گشتاسپ نشکیفتی   اندکی    اندکی   بار   یکی   و و\n",
            "Input26:     برو بر زدم بانگ برسان شیر \n",
            "Generated26: برو بر زدم بانگ برسان شیر    دلیر    پنیر پنیر و و   شیر شیر\n",
            "Input27:     جهان را ز کردار بد شرم نیست \n",
            "Generated27: جهان را ز کردار بد شرم نیست     نیست گاه بود و  اره نیست\n",
            "Input28:     فرستاد نزدیک رستم پیام \n",
            "Generated28: فرستاد نزدیک رستم پیام    نام نام    کام شام نام و \n",
            "Input29:     ببردند برزوی رانزد اوی \n",
            "Generated29: ببردند برزوی رانزد اوی   روی    و و   روی   جوی   اوی\n",
            "Input30:     چهارم سوی جنگ افراسیاب \n",
            "Generated30: چهارم سوی جنگ افراسیاب    آب    و   خواب دود و خواب \n",
            "Input31:     نباشد مرا باکسی داوری \n",
            "Generated31: نباشد مرا باکسی داوری    داوری کس گاه داوریبری   بری\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}